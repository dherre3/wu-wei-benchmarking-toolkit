#!/usr/bin/env node
var path = require('path')
var configLib = require(path.join(__dirname, '../lib/config'))
var nopt = require('nopt')
var noptUsage = require('nopt-usage')
var pointer = require('json-pointer')
var shelljs = require('shelljs')
var moment = require('moment')
var crypto = require('crypto')
var fs = require('fs')

var knownOpts = {
  'benchmark': [String, Array],
  'build': [String, Array],
  'clean': Boolean,
  'compiler': [String, Array],
  // 'experiment': String,
  'help': Boolean,
  'implementation': [String, Array],
  'input-size': String,
  'iteration-number': Number,
  'platform': String,
  'environment': [String, Array],
  'skip-output-verification': Boolean,
  'root': String,
  'verbose': Boolean
}
var shortHands = {
  'b': ['--benchmark'],
  'bu': ['--build'],
  'c': ['--compiler'],
  'en': ['--environment'],
  'e': ['--experiment'],
  'h': ['--help'],
  'i': ['--implementation'],
  'is': ['--input-size'],
  'n': ['--iteration-number'],
  'p': ['--platform'],
  'r': ['--root'],
  'v': ['--verbose']
}

var parsed = nopt(knownOpts, shortHands)
if (!parsed.root) {
  console.log('fatal: No benchmarking suite root directory provided')
  process.exit(1)
} else {
  var suiteRoot = path.resolve(process.cwd(), parsed.root)
}

if (parsed.clean) {
  shelljs.rm('-rf', path.join(suiteRoot, '/runs'))
  process.exit(0)
}

configLib.config(suiteRoot, function (err, config) {
  if (err) {
    console.log(err)
    process.exit(1)
  }

  var description = {
    'benchmark': "Benchmark's short-name, repeat to specify multiple benchmarks",
    'build': 'Build hash value, repeat to specify multiple builds',
    'clean': 'Clean the runs folder',
    'compiler': "Compiler's short-name, repeat to specify multiple compilers",
    'environment': "Environment's short-name, repeat to specify multiple environments",
    'experiment': 'Path to experiment configuration file',
    'help': 'Display this help',
    'implementation': "Implementation's short-name, repeat to specify multiple implementations",
    'input-size': 'One of [' + pointer.get(config.schema, '/definitions/experiment/properties/input-size/enum') + '], defaults to medium',
    'iteration-number': 'Number of times to execute the benchmark',
    'platform': 'Path to a configuration file describing the current hardware configuration',
    'root': 'Benchmark suite root',
    'skip-output-verification': 'Do not perform verification of output results'
  }

  if (parsed.help) {
    var usage = noptUsage(knownOpts, shortHands, description)
    console.log('usage: run [options] [short-name [short-name ...]]\n')
    console.log(
      'Runs builds on different environments. Defaults to all compatible builds\n' +
      'and all environments. Specify short-name(s) for benchmarks, implementations,\n' +
      'or compilers to run builds that match at least one name in each category specified.\n')
    console.log('positional arguments: ')
    console.log("  short-name\t\t\tbenchmark, implementation, or compiler's short-name. ")
    console.log('')
    console.log('optional arguments:')
    console.log(usage)
    process.exit(0)
  }

  // Load builds
  var run = {
    results: {},
    experiment: {
      'type': 'experiment',
      'short-name': 'default',
      'input-size': parsed['input-size'] || 'medium',
      'iteration-number': parsed['iteration-number'] || 1
    }
  }

  configLib.extractShortNames(config, parsed, run.experiment)

  var builds
  if (parsed.build) {
    builds = configLib.retrieveBuildsFromNames(config, parsed.build)
  } else {
    builds = configLib.genBuildConfigurations(config, {
      benchmarks: parsed.benchmarks.length > 0 ? parsed.benchmarks : config['benchmarks-list'],
      implementations: parsed.implementations.length > 0 ? parsed.implementations : config['implementation-list'],
      compilers: parsed.compilers.length > 0 ? parsed.compilers : config['compiler-list'],
      experiment: run.experiment
    })

    // Make sure to rebuild everything before running
    builds.forEach(function (buildConfig) {
      configLib.createRunner(buildConfig, parsed)
    })
  }

  if (builds.length === 0) {
    console.log('no builds to run')
    process.exit(1)
  }

  var runConfigs = configLib.genRunConfigurations(config, {
    benchmarks: parsed.benchmarks.length > 0 ? parsed.benchmarks : config['benchmarks-list'],
    implementations: parsed.implementations.length > 0 ? parsed.implementations : config['implementation-list'],
    compilers: parsed.compilers.length > 0 ? parsed.compilers : config['compiler-list'],
    environments: parsed.environments.length > 0 ? parsed.environments : config['environment-list'],
    experiment: run.experiment
  })

  var wuRunTmpDir = path.join(suiteRoot, '.wu', 'run-tmp')
  shelljs.mkdir('-p', wuRunTmpDir)
  shelljs.rm('-rf', path.join(wuRunTmpDir, '*'))

  runConfigs.forEach(function (runConfig) {
    runConfig.times = []
    runConfig.outputs = []

    console.log('-------------- ' + runConfig.benchmark['short-name'] +
      ',' + runConfig.implementation['short-name'] +
      ',' + runConfig.compiler['short-name'] +
      ',' + runConfig.platform['short-name'] +
      ',' + runConfig.environment['short-name'] +
      ' --------------')
    if (parsed.verbose) {
      console.log(runConfig.experiment)
    }

    var hashDigest = crypto
      .createHash('sha1')
      .update(JSON.stringify({
        benchmark: runConfig.benchmark,
        implementation: runConfig.implementation,
        compiler: runConfig.compiler,
        platform: runConfig.platform,
        environment: runConfig.environment,
        experiment: {
          'input-size': runConfig.experiment['input-size']
        }
      }))
      .digest('hex')

    var runConfigDir = path.join(wuRunTmpDir, hashDigest)
    shelljs.mkdir('-p', runConfigDir)

    for (var i = 0; i < run.experiment['iteration-number']; ++i) {
      var iterationDir = path.join(runConfigDir, String(i))
      shelljs.mkdir('-p', iterationDir)
      if (parsed.verbose) {
        console.log('************** Iteration ' + i + ' ************')
      }
      let silentState = shelljs.config.silent
      shelljs.config.silent = true
      shelljs.pushd(iterationDir)
      shelljs.config.silent = silentState

      var runOutput = configLib.executeRun(runConfig, parsed)
      var output = runOutput.output
      shelljs.config.silent = true
      shelljs.popd()
      shelljs.config.silent = silentState
      runConfig.times.push(output.time)
      runConfig.outputs.push(output)
      runConfig.cpuAvgLoad.push(runOutput.cpuAvgLoad)
    }

    var toWrite = configLib.deepcopy(run)
    toWrite.results[hashDigest] = runConfig

    var silentState = shelljs.config.silent
    shelljs.config.silent = true
    toWrite.time = moment().format('YYYY-MM-DDTHH:mm:ss:SSSZ')
    var dir = path.join(suiteRoot, 'runs', toWrite.time)
    shelljs.mkdir('-p', dir)
    shelljs.ln('-s', dir, path.join(suiteRoot, 'runs', 'latest'))
    fs.writeFileSync(path.join(dir, 'run.json'), JSON.stringify(toWrite, null, '  '))
    shelljs.cp('-r', path.join(wuRunTmpDir, '*'), dir)
    shelljs.config.silent = silentState
  })
  shelljs.rm('-rf', wuRunTmpDir)
})
